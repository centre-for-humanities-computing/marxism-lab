{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/knielbo/Documents/projects/baoding_lab\n"
     ]
    }
   ],
   "source": [
    "# core python\n",
    "import io, os\n",
    "\n",
    "# numerical/scientific computing\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# data management\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set envrionment\n",
    "##root_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "root_dir = os.path.dirname(os.path.abspath(\".\"))\n",
    "data_dir = os.path.join(\"..\", \"dat\")\n",
    "\n",
    "# MANAGING CLASSIFICATION DATA (from cl_build_data.py)\n",
    "DATA = pd.read_csv(os.path.join(data_dir,\"CLASS_DATA.csv\"), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of old_testament: 9461\n",
      "number of new_testament: 856\n",
      "Accuracy for free 0.92\n"
     ]
    }
   ],
   "source": [
    "## CLASS DIST AND BIAS\n",
    "def printdist(DF):\n",
    "    for label in set(DF['class']):\n",
    "        print(\"number of \" + label + \": {}\".format(sum(DF['class'] == label)))\n",
    "\n",
    "printdist(DATA)# BIASED\n",
    "print(\"Accuracy for free {}\".format(round(9461/float((9461+856)),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of old_testament: 800\n",
      "number of new_testament: 800\n"
     ]
    }
   ],
   "source": [
    "### UNBIAS DATA\n",
    "def balance(df, n, classcol = 'class'):\n",
    "    random.seed(1234)\n",
    "    res = pd.DataFrame(columns = DATA.columns)\n",
    "    C = list(set(df[classcol]))\n",
    "    for c in C:\n",
    "        idx = df[df[classcol] == c].index.tolist()\n",
    "        df_c = df.loc[random.sample(idx, n),]# label based indexing\n",
    "        res = res.append(df_c)\n",
    "    return res.reindex(np.random.permutation(res.index))#shuffle order for classifirer\n",
    "\n",
    "DATB = balance(DATA, 800)\n",
    "printdist(DATB)\n",
    "DATB.to_csv(\"../dat/CLASS_DATA_NONBIAS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA SET\n",
    "ratio = .8\n",
    "mask = np.random.rand(len(DATB)) <= ratio\n",
    "TRAIN = DATB[mask]\n",
    "TEST = DATB[~mask]\n",
    "\n",
    "## training set\n",
    "X_train = TRAIN['text'].values\n",
    "y_train = TRAIN['class'].values\n",
    "## test set\n",
    "X_test = TEST['text'].values\n",
    "y_test = TEST['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "DTM: [[0 1 1 1 0 0 0 1 0 1]\n",
      " [0 1 0 1 0 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 0 1 1 0]\n",
      " [0 1 1 2 0 1 0 1 0 2]]\n",
      "vocabulary (index): ['and', 'document', 'first', 'is', 'one', 'right', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "### INTERMEZZO: DOCUMENT REPRESENTATIONS AND UNDERSTANDING VECTORIZERS ###\n",
    "vectorizer = CountVectorizer()# INSTANTIATE VECTORIZER\n",
    "print(vectorizer)\n",
    "\n",
    "TEXTS = ['This is the first document.',\n",
    "        'This is the second second document.',\n",
    "        'And the third one.',\n",
    "        'Is this the first document? This is right.']\n",
    "\n",
    "DTM = vectorizer.fit_transform(TEXTS)\n",
    "\n",
    "print('DTM: {}'.format(DTM.todense()))\n",
    "print('vocabulary (index): {}'.format(vectorizer.get_feature_names()))\n",
    "\n",
    "# replace textmining with something more efficient\n",
    "np.savetxt(\"../dat/DTM.csv\", DTM.todense(), delimiter=\",\")\n",
    "lexicon = vectorizer.get_feature_names()\n",
    "with open('../dat/LEXICON.txt','w') as f:\n",
    "    for i in lexicon:\n",
    "        f.write(\"%s\\n\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION FOR UNSTRUCTURED DATA\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2), stop_words = 'english',\n",
    "    lowercase = True, max_df = .95, min_df = .01, max_features = 500)\n",
    "\n",
    "FEAT_train = vectorizer.fit_transform(X_train)# fit vector space\n",
    "FEAT_test =  vectorizer.transform(X_test)# !only transform, ignoring features not occurring in training set!\n",
    "FEAT_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN CLASSIFIER\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(FEAT_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurracy: 0.86\n",
      "K: 0.7319121447028424\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "new_testament       0.78      0.98      0.87       155\n",
      "old_testament       0.98      0.76      0.86       177\n",
      "\n",
      "     accuracy                           0.86       332\n",
      "    macro avg       0.88      0.87      0.86       332\n",
      " weighted avg       0.89      0.86      0.86       332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION\n",
    "pred = nb_classifier.predict(FEAT_test)\n",
    "confmat = metrics.confusion_matrix(y_test, pred)# horizontal: predicted label; vertical: true label\n",
    "# obeserved accuracy\n",
    "print(\"Accurracy: {}\".format(round(metrics.accuracy_score(y_test, pred),2)))\n",
    "\n",
    "# cohen's kappa\n",
    "print(\"K: {}\".format(metrics.cohen_kappa_score(y_test, pred)))\n",
    "# model summary\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADVANCED VALIDATION\n",
    "### obtain class possiblities\n",
    "y_scores = nb_classifier.fit(FEAT_train, y_train).predict_proba(FEAT_test)\n",
    "\n",
    "### ROC and AUC for ROC\n",
    "FPR, TPR, thresholds = metrics.roc_curve(y_test, y_scores[:,1], pos_label = 'old_testament')\n",
    "AUC = round(metrics.auc(FPR, TPR),2)# alternative Accurracy measure\n",
    "\n",
    "#### PLOT ROC\n",
    "plt.title('ROC')\n",
    "plt.plot(FPR, TPR, c='r', label=('AUC = {}'.format(AUC)))\n",
    "plt.legend(loc='lower right', prop={'size':8})\n",
    "plt.plot([0,1],[0,1], color='lightgrey', linestyle='--')\n",
    "plt.xlim([-0.01,1.0])\n",
    "plt.ylim([0.0,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('../fig/ROC.png', dpi = 300)\n",
    "plt.close()\n",
    "\n",
    "### precision-recall curve\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_scores[:,1], pos_label = 'old_testament')\n",
    "plt.title('PR Curve')\n",
    "plt.plot(recall, precision, c='r')\n",
    "plt.xlim([-0.01,1.0])\n",
    "plt.ylim([0.0,1.01])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('../fig/PRC.png', dpi = 300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xin",
   "language": "python",
   "name": "xin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
